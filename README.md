# PokeballGoLeague
A supervised machine learning project used to predict if user specified pokemon in "Pokemon Go" will be a competitive choice in the Master League PvP battle system

In the mobile game Pokemon Go, certain pokemon caught can have higher potential than others when used in the game. One of the most competitive aspects of this 
mobile game is the player versus player "Master League" battles. This gamemode allows the user to build a small team of 3 pokemon without a power cap- meaning that
higher level pokemon, particularly those that have the best battle statistics, are often chosen. Unfortunately, building a team that can perform well in Master League is
no easy task. It takes tremendous resources (called candy and stardust in game) to power many pokemon up to a competitive level which may involve months of "walking a pokemon" 
(this is how the game rewards players with candy and stardust) or even hundreds of pokemon catches. Therefore, having a way to tell which pokemon are worth investing the time and effort into
is more than useful tibbit of information.

This project is split up into 4 sections:

1. Data Generation:

Pokemon Go Master League has a "meta". This basically means that the majority of players use a specific subset of pokemon (the meta) in their battles because they often result in winning a match. This does not
mean that if a player doesnt use the meta they will lose- it actually means that there are now some datapoints for us to focus on! How does our pokemon compare to the meta? The current meta can be found at https://pokemongo.gamepress.gg/c/tier-lists/master-league-pvp-tier-list. These pokemon and important parameters are scraped and placed into "MasterLeague_Threats.csv" in data/processed/external. This file will most likely need to change ofen because the meta changes semi-regularly. Other important information needed to analyze how a pokemon ranks against the meta involves values specific to the pokemon: moves, base stats, is it a shadow form (means more attck but less defense), type effectiveness, combat power, level, evolutions, etc. The majority of this data is scraped from https://pogoapi.net/documentation/ and stored in data/processed/internal after the scripts "scraper.py" and "process_data.py" run. The script analyze_pokemon.py takes this information and calculates (effective) key battle parameters DPT (Damage Per Turn- damage a pokemon deals when it takes a turn), DPE (Damage Per Energy- energy generated allows a pokemon to build up to a charged attack, damage per energy shows the tradeoff between the two- inverse is energy per damage), and TDO (Total Damage Output- total damage dealt in a set battle length) by factoring in base stats, levels, Hit Points (HP), IVs (individual values; specific bonus stats when caught), available moves, special effects when a charged move is used (see data/processed/external/PVP_Charged_Move_Effects.csv), and STAB (Same Type Attack Bonus; a bonus that applies if the pokemon is the same type as the charged move it uses). Because of the way this is done, these battle parameters are only relevant within the datasets generated by and used to train the models within this application. Additionally, this allows for adaptability of the app when the meta changes or pokemon are added to the game.

The dataframe generated through analyze_pokemon.py has the following columns: is_shadow, form, pokemon_name, level, IV_atk, IV_def, IV_sta, CP, HP, TDO, DPT, DPE, and the reccomended moveset. The size of this dataset depends on the parameters fed to the script (ie. IV = [[14,15],[14,15],[14,15]) LEVEL = [30,35] will return the dataset for each combination of IV and level, in this case there would be 2^4 = 16 rows of data. This builds a large dataset very quick when IVS = [range(0, 16), range(0, 16), range(0, 16)], LEVELS = range(1, 51) for a complete picture of a pokemon's stat progression (204,800 rows at ~ 20MB). We can perform EDA on this database to buid a clear view of the multiplicative interactions between parameters and the battle stats. EDA on a single pokemon (I choose you, Melmetal) is enough to generalize for the rest because all pokemon in the game follow the same statistical logic.

2. Exploratory Data Analysis (EDA):

 For a complete 204,800 row database of Melmetal's stats we run an EDA using the EDA boolean in main.py, activating exploratory.py with the pokemon name and form. Dataframe columns for form, pokemon name, shadow, and all moves are dropped because they do not change in the matrix and are only in each row as an index for future data merging. We add a row for total IV (all 3 added together) for clarity on overall impact against the independent IVs impact during EDA.

First a correlation matrix between features is established:
 ![image](https://github.com/user-attachments/assets/f439ab58-42af-45db-84b7-54bc842eb4d2)
 
This matrix indicates that CP is (we can safely infer) 100% correlated with level. This is to be expected because CP is acutally calculated by multiplyijng the level by a CP multiplier that is unique for eaach pokemon. Both level and CP are also near 100% correlated to HP, TDO, DPT, and DPE (the battle stats). Because of this, We will exclude CP and HP from the pair plot generation. The pair plots are used to further examine the relationships of 'level', 'IV_atk', 'IV_def', 'IV_sta', 'IV_tot' on battle parameters DPT, DPE, and TDO:
![image](https://github.com/user-attachments/assets/a7b0ae76-e925-42dc-bb8e-435342da1002)

Plotting the relation of varying our parameters at different levels yields some interesting results. The first column of plots shows how each of our battle parameters changes when pokemon levels increase. Both DPE and DPT are shown to increase rapidly for the first 10 levels but gradually slow until level 30, at which point a linear increase in battle stat can be observed until level 50. Although DPT and DPE are strikingly similar, DPE differs in that the energy generated for each pokemon will depend on the moveset chosen, as some moves generate more energy than damage and each pokemon may experience different relationships between their own DPT and DPE (although the trend will match ours). TDO increases slowly at first but then grows rapidly until level 30 where it once again follows a near linear trend. As for the remainder of the plots, it is clear that the three battle stats are strongly influenced by IV_atk, but TDO in particular is also influenced by IV_def and IV_sta. We plot the influence per level for levels 10, 20, 30, 40, 50. It appears that the greater the level, the more the IV influences the battle stat. The final column shows how total IV influences battle stats and confirms that only attack IVs influence DPT and DPE, and that all three influence TDO. Finally we can check how each IV category impacts TDO. A feature importance between IVs and the TDO shows that stamina and attack are slightly more impactful than defense, although all three impact the outcome:
![image](https://github.com/user-attachments/assets/7f193776-35a3-47a1-83b1-8935bcfbe052)

This EDA gives an idea on what to include when training a model to predict which pokemon will do well in master league PvP. First of all, we know that we can drop either level or CP because they are basically refelective of one another. We remove level because each pokemon has a unique CP multiplier (meaning one pokemon's max CP will be different than anothers) so a match between CP and battle stats will lead to a stronger model. There are also some additional concepts to account for. First of all, pokemon have elemental types and elemental move types which can be super effective, neutral, or weak in battle. On top of this, pokemon can use shields twice in battle to block a charged attack! These alone obviously add tons of variety and edge cases to our already large database. Therefore, we simplify the process using script "battle_simulation.py"

3. Model Data Preparation 

There are a few ways to get the additional elemental typing and shield use data we need to train a model with. The most common way (used on https://pvpoke.com) is through simulating battles. Using this method each pokemon in the takes turns using fast attacks, charged moves, and shields. A battle score is given and a victor is determined. Although this project uses another way to determine a relative battle score and win/lose variable, if accuracy of predictions do not hold over time it may be changed to use that method. However, for now the battle score is calculated for each matchup by adjusting the battle parameters (TDO, DPE, DPT) by the elemental typing bonus or reduction. Shields are correlated to additional reductions in effective stats rather than rendering attacks useless due to the variability in battle (the opponent may or may not choose to shield an attack in certain situations). Finally the effective DPT is devided by DPE to get energy per turn, which is multiplied by TDO to get a rough battle performance score. Whichever pokemon gets the best highest performance score wins the matchup. Battle predictions are run for the specified pokemon at specified CP and IVs against all meta pokemon and the resulting dataframe with additional column "battle_score" is returned. This value is the average of the battle outcomes and essentially equates to the percentage of battles won in the meta (ie. battle_score = 0.25 is 25% win rate).

To build a full training/test dataset, analyze_pokemon.py and battle_simulation.py work together to output a battle.csv in data/models/app_calcs that includes all pokemon with a max cp above 3200 (time is wasted checking if a pokemon with max cp under 3200 will do well), testing their battle effieciencies (ie battle_score) across combinations of IVs = [[10,15],[10,15],[10,15]] with levels 30,35,40,45, and 50. These values should be enough to determine a trend and are actually the upper and lower limits of what is considered usable in master league. These values alone generate 40 rows for each pokemon, and there are over 200 pokemon that are elidgible for analysis. The final database takes over an hour to compile on my PC and has 10,640 rows (876KB). Unnecessary information for training such as name and level are dropped and the pokemon/move elemental types are encoded to integers. We set a threshold on what battle_score is considered an acceptable level to be viable. I wanted the model to be semi-leniant so I set this to be 25% battles won; setting a viability parameter column to 1 or 0 depending on this filter.
![image](https://github.com/user-attachments/assets/581c55d9-ffa5-4691-84b0-6b5f6f871928)

In all honesty, the incredible variation in Pokemon Go battles leads to a few assumptions: the battle_score is only an informed guess that loses credibility as it increases. Some pokemon perform much better than the battle score predicts due to a variety factors that would be much more intensive to integrate into this project (player skill, remaining health, team build, swapping out, etc). On the other side, pokemon that have a very low battle_score are very likely to do poorly in a real match because of their battle stats or typing. Therefore a battle_score threshold of 25% or lower gives a good idea if a pokemon is even worth considering for PvP.

4. Supervised Machine Learning Models:

There are two goals of this section: is pokemon viable for use in master league as is? What level is it viable for use in master league?
Answering these questions requires use of two models created in train_model.py... the first has to be a classifier of some sort. Which one do we use? Two capable models are Logistic Regression and Random Forest Classifier. Logistic Regression may capture the (basically) linear relation of certain battle stats to viability while eing computationally efficient, although there are some more complex interactions between elemental typing and other parameters that a Random Forest Classifier could account for. Each model is run on a training/test split of 80/20. Logistic Regression nunmber of max_iter had to be increased to 5000 to converge. The following parameters for RandomForestClassifier were used for the best results: max_depth=10, min_samples_split=5, min_samples_leaf=2, n_estimators=1000, random_state=42, class_weight="balanced". Parameter class_weight="balanced" was particularly useful because it helped tune the model to focus on datapoints where pokemon were viable in a dataset where the majority of pokemon datapoints were not (see battle.csv). Before this, the model overfit on instances where viability was 0, and would more often than not return a false negative. Accuracy of Random Forest Classifier was 0.9765 and accuracy of Logistic Regression was 0.9154 on the last run. The train_model.py script saves the most accurate one for answering the first question.

The second model we create must be a regression model in order to predict what particular minimulm level is viable. The dataset is once again modified and saved as a new file "battle_stats_delta". The data is modified such that the level for which each pokemon variation passes the threshold of battle_score into viability is linearly interpolated and stored. Then the variation of levels for each set of IVs is reduced so that one row is set with this interpolated level and all stats are replaced with the difference between the max and minimum level. THe reason this is done is beacause we will be training our model that an increase of battlestats across a set difference in levels corresponds with the minimum viable level specified. Now to train a model.

For this XGBoost Regression was chosen. XGBoost can handle complex interactions between parameters at a decent speed and efficiency (also thanks to parallelization) for such a large database. Other regression models such as standard Gradient Boost were too slow, especially when trying to tune hyperparameters. The following hyperparameter distribution was used to find the ideal model: "n_estimators": [100, 1000, 5000], "max_depth": [None, 3, 6, 9], "learning_rate": [0.01, 0.25, 0.5], "min_child_weight": [2, 4, 8], "gamma": [0.1, 0.2, 0.4]. Scoring was scoring="neg_mean_squared_error". These parameters help reduce overfitting and increase the capability to capture the multiparameter influence. The optimal model had mean squared error (MSE) of 2.067 and an r^2 of 0.9144 on the last run. The r squared shows that 91.44% of varience in the target variable is explained- this is very good. A MSE of 2.067 shows that the average minimum level predicted is around 1.5 lvels off. This is acceptable in a competitive environment where a level or two difference will probably not make or break the battle (the only consequence being that a guess of level 50 for a pokemon being viable could actually be level 51.5 which is not possible to reach- this can be adjusted for by setting edge conditions in our output).
![image](https://github.com/user-attachments/assets/e450354d-b2ae-4eae-9ef7-6d10a163ab78)

Finally the results are almost available. The first model returns viability of a given pokemon at it's current stats and the second model chimes in to provide insight on when such pokemon may be viable when leveled up. If it was viable long ago, the model will still report at what level this occured. If a pokemon is not viable as is and it cannot ever be, that is very sad. But the model will inform the user because the pokemon is currently not viable and the predicted minimum viable level was above level 50 (and a pokemon cannot typically get above this unless we get technical about it). The two models help increase the authenticity of the final decision. If model 1 undershoots (predicts a level 40 Kyogre is not viable) but model 2 predicts minimum viable level is 40 or lower, Kyogre will be updated to "viable". If model 1 overshoots (instead predicts a level 35 Kyogre is viable) but model 2 predicts minimum viable level is instead 42, a special output claiming "has potential as is" (semi-viability) will be shared although level 42 will still be reccomended for full viability.

Final Words

Pokemon Go battles are complicated. There are many assumptions made for the validity of data in this project that may or may not prove effective over time using this application. Parameter battle_score is only accurate in tight bounds and the estimations each model provides are educated guesses at best. In the future, a better dataset could be generated by legitimately simulating the battles between two pokemon. This application may serve as a convienient tool to a casual player who would like a quick and simple opinion on a pokemon as opposed than an in depth analysis that a highly competitive player would require. Overall, the models perform well but are only as accurate to reality as the data they are supplied with.

User Information:

In scripts/main.py: you do not need to change the booleans below, all models and data files are included in the repository

![image](https://github.com/user-attachments/assets/9ed4d4e4-47fc-4956-8c4a-4ac5311f956d)


To run a prediction from the models, run main.py updating these lines with the data of your pokemon. The machine learning models should be pre-loaded in data/models
the default entry of:
![image](https://github.com/user-attachments/assets/92c5ac6c-3ea0-481e-95bf-d6764160e535)


should yield this output:
Asking the machine if a [14, 14, 14] Melmetal at lvl 40 is viable in Master League...

       ----------------------------RESULTS-------------------------------
       A Melmetal at lvl 40 and IVs of [14, 14, 14] should have a CP of 3570
       ...you could use this Melmetal in Master League at these values!

       Acording to my calculations a Melmetal at or above level 33.5
                 should stand a chance in the Master League
       -----------------------------------------------------------------

Sources:
https://pokemongolive.com/?hl=en - game website
https://pvpoke.com/ -battle outcome validation
https://pogoapi.net/documentation/ -data used
https://db.pokemongohub.net/ -pokemon reference
